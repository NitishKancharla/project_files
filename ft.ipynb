{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45380df5-c65e-412c-88c9-3eb4dc002910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: nltk in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (3.9.1)\n",
      "Requirement already satisfied: pdfplumber in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.11.5)\n",
      "Requirement already satisfied: docx2txt in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (0.8)\n",
      "Requirement already satisfied: scikit-learn in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: torch in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (4.50.0)\n",
      "Requirement already satisfied: faiss-cpu in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.10.0)\n",
      "Requirement already satisfied: requests in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: gradio in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (5.22.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (77.0.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: click in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pdfplumber) (11.1.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pdfplumber) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: filelock in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy!=1.13.2,>=1.13.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (4.9.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.115.11)\n",
      "Requirement already satisfied: ffmpy in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.8.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (1.8.0)\n",
      "Requirement already satisfied: groovy~=0.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.1.2)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.28.1)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (3.0.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (3.10.15)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pydub in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: ruff>=0.9.3 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.11.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.46.1)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: websockets<16.0,>=10.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from sympy!=1.13.2,>=1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.1)\n",
      "Requirement already satisfied: wrapt in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: pycparser in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy nltk pdfplumber docx2txt scikit-learn torch transformers faiss-cpu requests gradio\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7b848b-ffaf-4908-aacb-c5872859eebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pdfplumber\n",
    "import docx2txt\n",
    "import requests\n",
    "import spacy\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f7d572-9bc6-4cf7-9b47-5357da2bd4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/nitish/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/nitish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/nitish/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53b7402a-6f13-40b8-9352-35623ba29142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://99ac9879a5737a7a70.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://99ac9879a5737a7a70.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pdfplumber\n",
    "import spacy\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Initialize spaCy and Gemini API\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "genai.configure(api_key=\"AIzaSyDS0SXbtLKaawt2IdjTezO8HzsaSoM6RJM\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define job roles and required skills, and job descriptions\n",
    "JOB_ROLES = {\n",
    "    \"Data Scientist\": {\n",
    "        \"skills\": {\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Statistics\", \"Pandas\", \"Scikit-Learn\"},\n",
    "        \"description\": \"\"\"We are seeking a Data Scientist to analyze complex datasets, develop machine learning models, and provide actionable insights. The ideal candidate should have strong skills in Python, SQL, and various machine learning techniques.\"\"\"\n",
    "    },\n",
    "    \"Software Engineer\": {\n",
    "        \"skills\": {\"Python\", \"Java\", \"C++\", \"Git\", \"OOP\", \"Algorithms\"},\n",
    "        \"description\": \"\"\"We are looking for a Software Engineer to develop and maintain high-quality software applications. The candidate should be proficient in Python, Java, or C++, and have a good understanding of object-oriented programming and algorithms.\"\"\"\n",
    "    },\n",
    "    \"Cloud Engineer\": {\n",
    "        \"skills\": {\"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Terraform\", \"Networking\"},\n",
    "        \"description\": \"\"\"We need a Cloud Engineer to manage and optimize our cloud infrastructure. The candidate should have experience with AWS or Azure, Docker, Kubernetes, and Terraform.\"\"\"\n",
    "    },\n",
    "    \"Cybersecurity Analyst\": {\n",
    "        \"skills\": {\"Cybersecurity\", \"Ethical Hacking\", \"Network Security\", \"Penetration Testing\"},\n",
    "        \"description\": \"\"\"We are hiring a Cybersecurity Analyst to protect our systems from cyber threats. The candidate should have expertise in ethical hacking, network security, and penetration testing.\"\"\"\n",
    "    },\n",
    "    \"AI Engineer\": {\n",
    "        \"skills\": {\"Python\", \"TensorFlow\", \"PyTorch\", \"Machine Learning\", \"Deep Learning\", \"AI\"},\n",
    "        \"description\": \"\"\"We're looking for an AI Engineer to build and deploy advanced AI models. Proficiency in Python, TensorFlow, and PyTorch is essential.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Predefined common skills\n",
    "COMMON_SKILLS = {\n",
    "    \"Python\", \"Java\", \"C++\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Pandas\", \"Scikit-Learn\",\n",
    "    \"TensorFlow\", \"PyTorch\", \"Data Analysis\", \"Cybersecurity\", \"Ethical Hacking\", \"AWS\", \"Azure\", \"Docker\",\n",
    "    \"Kubernetes\", \"Flask\", \"Django\", \"Linux\", \"JavaScript\", \"React\", \"Node.js\", \"Computer Vision\", \"Statistics\",\n",
    "    \"Mathematics\", \"Tableau\", \"Power BI\", \"Time Management\", \"Problem Solving\", \"Communication\", \"Teamwork\"\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text if text else \"Error extracting text from PDF\"\n",
    "\n",
    "def extract_resume_data(text):\n",
    "    \"\"\"Extract resume data as JSON, including skills and summary.\"\"\"\n",
    "    extracted_skills = set()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Match predefined skills\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if skill.lower() in text_lower:\n",
    "            extracted_skills.add(skill)\n",
    "\n",
    "    # Use spaCy for Named Entity Recognition (NER)\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"PERSON\", \"GPE\", \"FACILITY\", \"EVENT\"]:  # Avoid extracting non-skills\n",
    "            continue\n",
    "        if ent.text in COMMON_SKILLS:  # Extract only valid skills\n",
    "            extracted_skills.add(ent.text)\n",
    "\n",
    "    # Extract summary\n",
    "    summary = \"Summary not found.\"\n",
    "    for sent in doc.sents:\n",
    "        if len(sent.text.split()) > 5:\n",
    "            summary = sent.text\n",
    "            break\n",
    "\n",
    "    resume_data = {\n",
    "        \"skills\": list(extracted_skills),\n",
    "        \"summary\": summary\n",
    "    }\n",
    "    return json.dumps(resume_data, indent=4)\n",
    "\n",
    "def calculate_match_score_with_llm(resume_json, job_description, job_skills):\n",
    "    \"\"\"Calculate match score using Gemini LLM and provide detailed analysis.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following resume data in JSON format:\n",
    "    {resume_json}\n",
    "\n",
    "    And the following job description:\n",
    "    {job_description}\n",
    "\n",
    "    And the following job required skills:\n",
    "    {job_skills}\n",
    "\n",
    "    Analyze the resume data and determine the match score as a percentage.\n",
    "    List the skills that matched and the skills that did not match.\n",
    "    Provide a brief explanation of why you gave the score.\n",
    "    Return the score, matched skills, unmatched skills, and explanation in a JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    try:\n",
    "        response_text = response.text\n",
    "        start_index = response_text.find('{')\n",
    "        end_index = response_text.rfind('}') + 1\n",
    "        json_output = json.loads(response_text[start_index:end_index])\n",
    "        return json_output\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return {\"score\": 0, \"matched_skills\": [], \"unmatched_skills\": [], \"explanation\": \"Failed to calculate match score.\"}\n",
    "\n",
    "def process_resume(file, job_role):\n",
    "    \"\"\"Process resume, extract data, and calculate match score using LLM.\"\"\"\n",
    "    resume_text = extract_text_from_pdf(file.name)\n",
    "    resume_json = extract_resume_data(resume_text)\n",
    "    job_description = JOB_ROLES[job_role][\"description\"]\n",
    "    job_skills = JOB_ROLES[job_role][\"skills\"]\n",
    "    match_result = calculate_match_score_with_llm(resume_json, job_description, job_skills)\n",
    "\n",
    "    return f\" **Resume Data (JSON):**\\n{resume_json}\\n\\n\" \\\n",
    "           f\" **Match Score:** {match_result.get('score', 0)}%\\n\\n\" \\\n",
    "           f\" **Matched Skills:** {', '.join(match_result.get('matched_skills', []))}\\n\\n\" \\\n",
    "           f\" **Unmatched Skills:** {', '.join(match_result.get('unmatched_skills', []))}\\n\\n\" \\\n",
    "           f\" **Explanation:** {match_result.get('explanation', 'No explanation available.')}\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 📄 Resume Matcher using LLM\")\n",
    "    gr.Markdown(\"Upload your resume and select a job role to check your match score using LLM.\")\n",
    "\n",
    "    file_input = gr.File(label=\"Upload Resume (PDF)\")\n",
    "    job_dropdown = gr.Dropdown(choices=list(JOB_ROLES.keys()), label=\"Select Job Role\")\n",
    "    output_text = gr.Textbox(label=\"Result\", interactive=False)\n",
    "\n",
    "    submit_button = gr.Button(\"Check Match Score\")\n",
    "    submit_button.click(fn=process_resume, inputs=[file_input, job_dropdown], outputs=output_text)\n",
    "\n",
    "# Run the Gradio app\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "243f956c-752a-4363-bef7-bc9f702dc114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://17e6cadcd6363529d4.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://17e6cadcd6363529d4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pdfplumber\n",
    "import spacy\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Initialize spaCy and Gemini API\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "genai.configure(api_key=\"AIzaSyDS0SXbtLKaawt2IdjTezO8HzsaSoM6RJM\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define job roles and required skills, and job descriptions\n",
    "JOB_ROLES = {\n",
    "    \"Data Scientist\": {\n",
    "        \"skills\": {\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Statistics\", \"Pandas\", \"Scikit-Learn\"},\n",
    "        \"description\": \"\"\"We are seeking a Data Scientist to analyze complex datasets, develop machine learning models, and provide actionable insights. The ideal candidate should have strong skills in Python, SQL, and various machine learning techniques.\"\"\"\n",
    "    },\n",
    "    \"Software Engineer\": {\n",
    "        \"skills\": {\"Python\", \"Java\", \"C++\", \"Git\", \"OOP\", \"Algorithms\"},\n",
    "        \"description\": \"\"\"We are looking for a Software Engineer to develop and maintain high-quality software applications. The candidate should be proficient in Python, Java, or C++, and have a good understanding of object-oriented programming and algorithms.\"\"\"\n",
    "    },\n",
    "    \"Cloud Engineer\": {\n",
    "        \"skills\": {\"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Terraform\", \"Networking\"},\n",
    "        \"description\": \"\"\"We need a Cloud Engineer to manage and optimize our cloud infrastructure. The candidate should have experience with AWS or Azure, Docker, Kubernetes, and Terraform.\"\"\"\n",
    "    },\n",
    "    \"Cybersecurity Analyst\": {\n",
    "        \"skills\": {\"Cybersecurity\", \"Ethical Hacking\", \"Network Security\", \"Penetration Testing\"},\n",
    "        \"description\": \"\"\"We are hiring a Cybersecurity Analyst to protect our systems from cyber threats. The candidate should have expertise in ethical hacking, network security, and penetration testing.\"\"\"\n",
    "    },\n",
    "    \"AI Engineer\": {\n",
    "        \"skills\": {\"Python\", \"TensorFlow\", \"PyTorch\", \"Machine Learning\", \"Deep Learning\", \"AI\"},\n",
    "        \"description\": \"\"\"We're looking for an AI Engineer to build and deploy advanced AI models. Proficiency in Python, TensorFlow, and PyTorch is essential.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Predefined common skills\n",
    "COMMON_SKILLS = {\n",
    "    \"Python\", \"Java\", \"C++\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Pandas\", \"Scikit-Learn\",\n",
    "    \"TensorFlow\", \"PyTorch\", \"Data Analysis\", \"Cybersecurity\", \"Ethical Hacking\", \"AWS\", \"Azure\", \"Docker\",\n",
    "    \"Kubernetes\", \"Flask\", \"Django\", \"Linux\", \"JavaScript\", \"React\", \"Node.js\", \"Computer Vision\", \"Statistics\",\n",
    "    \"Mathematics\", \"Tableau\", \"Power BI\", \"Time Management\", \"Problem Solving\", \"Communication\", \"Teamwork\"\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text if text else \"Error extracting text from PDF\"\n",
    "\n",
    "def extract_resume_data(text):\n",
    "    \"\"\"Extract resume data as JSON, including skills and summary.\"\"\"\n",
    "    extracted_skills = set()\n",
    "    text_lower = text.lower()\n",
    "\n",
    "    # Match predefined skills\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if skill.lower() in text_lower:\n",
    "            extracted_skills.add(skill)\n",
    "\n",
    "    # Use spaCy for Named Entity Recognition (NER)\n",
    "    doc = nlp(text)\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"PERSON\", \"GPE\", \"FACILITY\", \"EVENT\"]:  # Avoid extracting non-skills\n",
    "            continue\n",
    "        if ent.text in COMMON_SKILLS:  # Extract only valid skills\n",
    "            extracted_skills.add(ent.text)\n",
    "\n",
    "    # Extract summary\n",
    "    summary = \"Summary not found.\"\n",
    "    for sent in doc.sents:\n",
    "        if len(sent.text.split()) > 5:\n",
    "            summary = sent.text\n",
    "            break\n",
    "\n",
    "    resume_data = {\n",
    "        \"skills\": list(extracted_skills),\n",
    "        \"summary\": summary\n",
    "    }\n",
    "    return json.dumps(resume_data, indent=4)\n",
    "\n",
    "def calculate_match_score_with_llm(resume_json, job_description, job_skills):\n",
    "    \"\"\"Calculate match score using Gemini LLM and provide detailed analysis and improvement tips.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following resume data in JSON format:\n",
    "    {resume_json}\n",
    "\n",
    "    And the following job description:\n",
    "    {job_description}\n",
    "\n",
    "    And the following job required skills:\n",
    "    {job_skills}\n",
    "\n",
    "    Analyze the resume data and determine the match score as a percentage.\n",
    "    List the skills that matched and the skills that did not match.\n",
    "    Provide a detailed explanation of why you gave the score, and provide advice to the candidate on how to improve the missing skills to match the job role.\n",
    "    Return the score, matched skills, unmatched skills, and explanation and improvement tips in a JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    try:\n",
    "        response_text = response.text\n",
    "        start_index = response_text.find('{')\n",
    "        end_index = response_text.rfind('}') + 1\n",
    "        json_output = json.loads(response_text[start_index:end_index])\n",
    "        return json_output\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return {\"score\": 0, \"matched_skills\": [], \"unmatched_skills\": [], \"explanation\": \"Failed to calculate match score.\", \"improvement_tips\": \"Failed to provide improvement tips.\"}\n",
    "\n",
    "def process_resume(file, job_role):\n",
    "    \"\"\"Process resume, extract data, and calculate match score using LLM.\"\"\"\n",
    "    resume_text = extract_text_from_pdf(file.name)\n",
    "    resume_json = extract_resume_data(resume_text)\n",
    "    job_description = JOB_ROLES[job_role][\"description\"]\n",
    "    job_skills = JOB_ROLES[job_role][\"skills\"]\n",
    "    match_result = calculate_match_score_with_llm(resume_json, job_description, job_skills)\n",
    "    matched_skills = match_result.get('matched_skills', [])\n",
    "    unmatched_skills = match_result.get('unmatched_skills', [])\n",
    "    job_skills_set = JOB_ROLES[job_role]['skills']\n",
    "    calculated_score = 0\n",
    "    if len(job_skills_set) > 0 :\n",
    "        calculated_score = (len(set(matched_skills).intersection(job_skills_set)) / len(job_skills_set)) * 100\n",
    "\n",
    "    return f\" **Resume Data (JSON):**\\n{resume_json}\\n\\n\" \\\n",
    "           f\" **Match Score:** {calculated_score}%\\n\\n\" \\\n",
    "           f\" **Matched Skills:** {', '.join(matched_skills)}\\n\\n\" \\\n",
    "           f\" **Unmatched Skills:** {', '.join(unmatched_skills)}\\n\\n\" \\\n",
    "           f\" **Explanation:** {match_result.get('explanation', 'No explanation available.')}\\n\\n\" \\\n",
    "           f\" **Improvement Tips:** {match_result.get('improvement_tips', 'No improvement tips available.')}\"\n",
    "\n",
    "# Gradio UI\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 📄 Resume Matcher using LLM\")\n",
    "    gr.Markdown(\"Upload your resume and select a job role to check your match score using LLM.\")\n",
    "\n",
    "    file_input = gr.File(label=\"Upload Resume (PDF)\")\n",
    "    job_dropdown = gr.Dropdown(choices=list(JOB_ROLES.keys()), label=\"Select Job Role\")\n",
    "    output_text = gr.Textbox(label=\"Result\", interactive=False)\n",
    "\n",
    "    submit_button = gr.Button(\"Check Match Score\")\n",
    "    submit_button.click(fn=process_resume, inputs=[file_input, job_dropdown], outputs=output_text)\n",
    "\n",
    "# Run the Gradio app\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c176a3-1465-41ff-b59f-d0755c6a3bf9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 88) (430324283.py, line 88)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 88\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdata[\".\u001b[39m\n         ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 88)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pdfplumber\n",
    "import spacy\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "# Initialize spaCy and Gemini API\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "genai.configure(api_key=\"AIzaSyDS0SXbtLKaawt2IdjTezO8HzsaSoM6RJM\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define job roles and required skills, and job descriptions\n",
    "JOB_ROLES = {\n",
    "    \"Data Scientist\": {\n",
    "        \"skills\": {\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Statistics\", \"Pandas\", \"Scikit-Learn\"},\n",
    "        \"description\": \"\"\"We are seeking a Data Scientist to analyze complex datasets, develop machine learning models, and provide actionable insights. The ideal candidate should have strong skills in Python, SQL, and various machine learning techniques.\"\"\"\n",
    "    },\n",
    "    \"Software Engineer\": {\n",
    "        \"skills\": {\"Python\", \"Java\", \"C++\", \"Git\", \"OOP\", \"Algorithms\"},\n",
    "        \"description\": \"\"\"We are looking for a Software Engineer to develop and maintain high-quality software applications. The candidate should be proficient in Python, Java, or C++, and have a good understanding of object-oriented programming and algorithms.\"\"\"\n",
    "    },\n",
    "    \"Cloud Engineer\": {\n",
    "        \"skills\": {\"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Terraform\", \"Networking\"},\n",
    "        \"description\": \"\"\"We need a Cloud Engineer to manage and optimize our cloud infrastructure. The candidate should have experience with AWS or Azure, Docker, Kubernetes, and Terraform.\"\"\"\n",
    "    },\n",
    "    \"Cybersecurity Analyst\": {\n",
    "        \"skills\": {\"Cybersecurity\", \"Ethical Hacking\", \"Network Security\", \"Penetration Testing\"},\n",
    "        \"description\": \"\"\"We are hiring a Cybersecurity Analyst to protect our systems from cyber threats. The candidate should have expertise in ethical hacking, network security, and penetration testing.\"\"\"\n",
    "    },\n",
    "    \"AI Engineer\": {\n",
    "        \"skills\": {\"Python\", \"TensorFlow\", \"PyTorch\", \"Machine Learning\", \"Deep Learning\", \"AI\"},\n",
    "        \"description\": \"\"\"We're looking for an AI Engineer to build and deploy advanced AI models. Proficiency in Python, TensorFlow, and PyTorch is essential.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Predefined common skills\n",
    "COMMON_SKILLS = {\n",
    "    \"Python\", \"Java\", \"C++\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Pandas\", \"Scikit-Learn\",\n",
    "    \"TensorFlow\", \"PyTorch\", \"Data Analysis\", \"Cybersecurity\", \"Ethical Hacking\", \"AWS\", \"Azure\", \"Docker\",\n",
    "    \"Kubernetes\", \"Flask\", \"Django\", \"Linux\", \"JavaScript\", \"React\", \"Node.js\", \"Computer Vision\", \"Statistics\",\n",
    "    \"Mathematics\", \"Tableau\", \"Power BI\", \"Time Management\", \"Problem Solving\", \"Communication\", \"Teamwork\"\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text if text else \"Error extracting text from PDF\"\n",
    "\n",
    "def extract_resume_data(text):\n",
    "    \"\"\"Extract detailed resume data as JSON.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    data = {\n",
    "        \"personal\": {\n",
    "            \"name\": \"\",\n",
    "            \"phone\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"address\": \"\",\n",
    "            \"gender\": \"\",\n",
    "            \"date_of_birth\": \"\",\n",
    "            \"social\": [],\n",
    "            \"about\": \"\"\n",
    "        },\n",
    "        \"skills\": [],\n",
    "        \"education\": [],\n",
    "        \"experience\": [],\n",
    "        \"overall_experience\": \"\"\n",
    "    }\n",
    "\n",
    "    # Personal Information Extraction\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and not data[\"personal\"][\"name\"]:\n",
    "            data[\"personal\"][\"name\"] = ent.text\n",
    "        elif ent.label_ == \"GPE\" and not data[\"personal\"][\"address\"]:\n",
    "            data[\"personal\"][\"address\"] = ent.text\n",
    "        elif ent.label_ == \"DATE\" and not data[\"personal\"][\"date_of_birth\"]:\n",
    "            data[\"personal\"][\"date_of_birth\"] = ent.text\n",
    "\n",
    "    phone_match = re.search(r'(\\+\\d{1,3}\\s?)?(\\(\\d{3}\\)\\s?)?(\\d{3}[-\\.\\s]??\\d{4}|\\d{10})', text)\n",
    "    if phone_match:\n",
    "        data[\"personal\"][\"phone\"] = phone_match.group(0)\n",
    "\n",
    "    email_match = re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "    if email_match:\n",
    "        data[\".\n",
    "        personal\"][\"email\"] = email_match.group(0)\n",
    "\n",
    "    social_matches = re.findall(r\"(https?://[^\\s]+)\", text)\n",
    "    data[\"personal\"][\"social\"] = social_matches\n",
    "\n",
    "    # Skills Extraction\n",
    "    text_lower = text.lower()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if skill.lower() in text_lower:\n",
    "            data[\"skills\"].append({\"name\": skill, \"type\": \"technical\", \"experience\": \"1\"})\n",
    "\n",
    "    # Education and Experience Extraction (Simplified)\n",
    "    education_matches = re.findall(r\"(Bachelor|Master|Ph\\.D)\\s+of\\s+([\\w\\s]+)\\s+from\\s+([\\w\\s]+)\\s+(?:(\\d{4}-\\d{4}|\\d{4}-\\w+))\", text, re.IGNORECASE)\n",
    "    for degree, field, institution, dates in education_matches:\n",
    "        data[\"education\"].append({\"degree\": f\"{degree} of {field}\", \"institution\": institution, \"dates\": dates})\n",
    "\n",
    "    experience_matches = re.findall(r\"([\\w\\s]+)\\s+at\\s+([\\w\\s]+)\\s+(?:(\\d{4}-\\d{4}|\\d{4}-\\w+))\\s+([\\w\\s,]+)\", text)\n",
    "    for title, company, dates, location in experience_matches:\n",
    "        data[\"experience\"].append({\"title\": title, \"company\": company, \"dates\": dates, \"location\": location})\n",
    "\n",
    "    # Summary/About\n",
    "    for sent in doc.sents:\n",
    "        if len(sent.text.split()) > 10:\n",
    "            data['personal']['about'] += sent.text\n",
    "\n",
    "    return json.dumps(data, indent=4)\n",
    "\n",
    "def calculate_match_score_with_llm(resume_json, job_description, job_skills):\n",
    "    \"\"\"Calculate match score using Gemini LLM and provide detailed analysis and improvement tips.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following resume data in JSON format:\n",
    "    {resume_json}\n",
    "\n",
    "    And the following job description:\n",
    "    {job_description}\n",
    "\n",
    "    And the following job required skills:\n",
    "    {job_skills}\n",
    "\n",
    "    Analyze the resume data and determine the match score as a percentage.\n",
    "    List the skills that matched and the skills that did not match.\n",
    "    Provide a detailed explanation of why you gave the score, and provide advice to the candidate on how to improve the missing skills to match the job role.\n",
    "    Return the score, matched skills, unmatched skills, and explanation and improvement tips in a JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    try:\n",
    "        response_text = response.text\n",
    "        start_index = response_text.find('{')\n",
    "        end_index = response_text.rfind('}') + 1\n",
    "        json_output = json.loads(response_text[start_index:end_index])\n",
    "        return json_output\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return {\"score\": 0, \"matched_skills\": [], \"unmatched_skills\": [], \"explanation\": \"Failed to calculate match score.\", \"improvement_tips\": \"Failed to provide improvement tips.\"}\n",
    "\n",
    "def process_resume(file, job_role):\n",
    "    \"\"\"Process resume, extract data, and calculate match score using LLM.\"\"\"\n",
    "    resume_text = extract_text_from_pdf(file.name)\n",
    "    resume_json = extract_resume_data(resume_text)\n",
    "    job_description = JOB_ROLES[job_role][\"description\"]\n",
    "    job_skills = JOB_ROLES[job_role][\"skills\"]\n",
    "    match_result = calculate_match_score_with_llm(resume_json, job_description, job_skills)\n",
    "    matched_skills = match_result.get('matched_skills', [])\n",
    "    unmatched_skills = match_result.get('unmatched_skills', [])\n",
    "    job_skills_set = JOB_ROLES[job_role]['skills']\n",
    "    calculated_score = 0\n",
    "    if len(job_skills_set) > 0:\n",
    "        calculated_score = len(matched_skills) / len(job_skills_set) * 100\n",
    "    return {\n",
    "        \"match_score\": calculated_score,\n",
    "        \"matched_skills\": matched_skills,\n",
    "        \"unmatched_skills\": unmatched_skills,\n",
    "        \"job_description\": job_description,\n",
    "        \"resume_data\": resume_json\n",
    "    }\n",
    "\n",
    "# Create the Gradio interface for file upload and job role selection\n",
    "def gradio_interface():\n",
    "    job_roles = list(JOB_ROLES.keys())\n",
    "    \n",
    "    def gradio_function(resume_file, job_role):\n",
    "        return process_resume(resume_file, job_role)\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=gradio_function,\n",
    "        inputs=[gr.File(label=\"Upload Resume\"), gr.Dropdown(choices=job_roles, label=\"Job Role\", value=job_roles[0])],\n",
    "        outputs=\"json\"\n",
    "    )\n",
    "\n",
    "    iface.launch()\n",
    "\n",
    "# Start Gradio interface\n",
    "gradio_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f458d5-4c4e-47ba-9225-693724b899cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import pdfplumber\n",
    "import spacy\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "\n",
    "# Initialize spaCy and Gemini API\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "genai.configure(api_key=\"AIzaSyDS0SXbtLKaawt2IdjTezO8HzsaSoM6RJM\")\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "\n",
    "# Define job roles and required skills, and job descriptions\n",
    "JOB_ROLES = {\n",
    "    \"Data Scientist\": {\n",
    "        \"skills\": {\"Python\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Statistics\", \"Pandas\", \"Scikit-Learn\"},\n",
    "        \"description\": \"\"\"We are seeking a Data Scientist to analyze complex datasets, develop machine learning models, and provide actionable insights. The ideal candidate should have strong skills in Python, SQL, and various machine learning techniques.\"\"\"\n",
    "    },\n",
    "    \"Software Engineer\": {\n",
    "        \"skills\": {\"Python\", \"Java\", \"C++\", \"Git\", \"OOP\", \"Algorithms\"},\n",
    "        \"description\": \"\"\"We are looking for a Software Engineer to develop and maintain high-quality software applications. The candidate should be proficient in Python, Java, or C++, and have a good understanding of object-oriented programming and algorithms.\"\"\"\n",
    "    },\n",
    "    \"Cloud Engineer\": {\n",
    "        \"skills\": {\"AWS\", \"Azure\", \"Docker\", \"Kubernetes\", \"Terraform\", \"Networking\"},\n",
    "        \"description\": \"\"\"We need a Cloud Engineer to manage and optimize our cloud infrastructure. The candidate should have experience with AWS or Azure, Docker, Kubernetes, and Terraform.\"\"\"\n",
    "    },\n",
    "    \"Cybersecurity Analyst\": {\n",
    "        \"skills\": {\"Cybersecurity\", \"Ethical Hacking\", \"Network Security\", \"Penetration Testing\"},\n",
    "        \"description\": \"\"\"We are hiring a Cybersecurity Analyst to protect our systems from cyber threats. The candidate should have expertise in ethical hacking, network security, and penetration testing.\"\"\"\n",
    "    },\n",
    "    \"AI Engineer\": {\n",
    "        \"skills\": {\"Python\", \"TensorFlow\", \"PyTorch\", \"Machine Learning\", \"Deep Learning\", \"AI\"},\n",
    "        \"description\": \"\"\"We're looking for an AI Engineer to build and deploy advanced AI models. Proficiency in Python, TensorFlow, and PyTorch is essential.\"\"\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Predefined common skills\n",
    "COMMON_SKILLS = {\n",
    "    \"Python\", \"Java\", \"C++\", \"SQL\", \"Machine Learning\", \"Deep Learning\", \"NLP\", \"Pandas\", \"Scikit-Learn\",\n",
    "    \"TensorFlow\", \"PyTorch\", \"Data Analysis\", \"Cybersecurity\", \"Ethical Hacking\", \"AWS\", \"Azure\", \"Docker\",\n",
    "    \"Kubernetes\", \"Flask\", \"Django\", \"Linux\", \"JavaScript\", \"React\", \"Node.js\", \"Computer Vision\", \"Statistics\",\n",
    "    \"Mathematics\", \"Tableau\", \"Power BI\", \"Time Management\", \"Problem Solving\", \"Communication\", \"Teamwork\"\n",
    "}\n",
    "\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_file) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "    return text if text else \"Error extracting text from PDF\"\n",
    "\n",
    "def extract_resume_data(text):\n",
    "    \"\"\"Extract detailed resume data as JSON.\"\"\"\n",
    "    doc = nlp(text)\n",
    "    data = {\n",
    "        \"personal\": {\n",
    "            \"name\": \"\",\n",
    "            \"phone\": \"\",\n",
    "            \"email\": \"\",\n",
    "            \"address\": \"\",\n",
    "            \"gender\": \"\",\n",
    "            \"date_of_birth\": \"\",\n",
    "            \"social\": [],\n",
    "            \"about\": \"\"\n",
    "        },\n",
    "        \"skills\": [],\n",
    "        \"education\": [],\n",
    "        \"experience\": [],\n",
    "        \"overall_experience\": \"missing\"\n",
    "    }\n",
    "\n",
    "    # Personal Information Extraction\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"PERSON\" and not data[\"personal\"][\"name\"]:\n",
    "            data[\"personal\"][\"name\"] = ent.text\n",
    "        elif ent.label_ == \"GPE\" and not data[\"personal\"][\"address\"]:\n",
    "            data[\"personal\"][\"address\"] = ent.text\n",
    "        elif ent.label_ == \"DATE\" and not data[\"personal\"][\"date_of_birth\"]:\n",
    "            data[\"personal\"][\"date_of_birth\"] = ent.text\n",
    "\n",
    "    phone_match = re.search(r'(\\+\\d{1,3}\\s?)?(\\(\\d{3}\\)\\s?)?(\\d{3}[-\\.\\s]??\\d{4}|\\d{10})', text)\n",
    "    if phone_match:\n",
    "        data[\"personal\"][\"phone\"] = phone_match.group(0)\n",
    "\n",
    "    email_match = re.search(r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\", text)\n",
    "    if email_match:\n",
    "        data[\"personal\"][\"email\"] = email_match.group(0)\n",
    "\n",
    "    social_matches = re.findall(r\"(https?://[^\\s]+)\", text)\n",
    "    data[\"personal\"][\"social\"] = social_matches\n",
    "\n",
    "    # Skills Extraction\n",
    "    text_lower = text.lower()\n",
    "    for skill in COMMON_SKILLS:\n",
    "        if skill.lower() in text_lower:\n",
    "            data[\"skills\"].append({\"name\": skill, \"type\": \"technical\", \"experience\": \"1\"})\n",
    "\n",
    "    # Education and Experience Extraction (Simplified)\n",
    "    education_matches = re.findall(r\"(Bachelor|Master|Ph\\.D)\\s+of\\s+([\\w\\s]+)\\s+from\\s+([\\w\\s]+)\\s+(?:(\\d{4}-\\d{4}|\\d{4}-\\w+))\", text, re.IGNORECASE)\n",
    "    for degree, field, institution, dates in education_matches:\n",
    "        data[\"education\"].append({\"degree\": f\"{degree} of {field}\", \"institution\": institution, \"dates\": dates})\n",
    "\n",
    "    experience_matches = re.findall(r\"([\\w\\s]+)\\s+at\\s+([\\w\\s]+)\\s+(?:(\\d{4}-\\d{4}|\\d{4}-\\w+))\\s+([\\w\\s,]+)\", text)\n",
    "    for title, company, dates, location in experience_matches:\n",
    "        data[\"experience\"].append({\"title\": title, \"company\": company, \"dates\": dates, \"location\": location})\n",
    "\n",
    "    # Summary/About\n",
    "    for sent in doc.sents:\n",
    "        if len(sent.text.split()) > 10:\n",
    "            data['personal']['about'] += sent.text\n",
    "\n",
    "    # Handle missing values after extraction\n",
    "    for key, value in data[\"personal\"].items():\n",
    "        if not value and key != \"social\":  # social can be an empty list\n",
    "            data[\"personal\"][key] = \"missing\"\n",
    "    if not data[\"skills\"]:\n",
    "        data[\"skills\"] = []\n",
    "    if not data[\"education\"]:\n",
    "        data[\"education\"] = []\n",
    "    if not data[\"experience\"]:\n",
    "        data[\"experience\"] = []\n",
    "    if not data[\"overall_experience\"]:\n",
    "        data[\"overall_experience\"] = \"missing\"\n",
    "\n",
    "    return json.dumps(data, indent=4)\n",
    "\n",
    "def calculate_match_score_with_llm(resume_json, job_description, job_skills):\n",
    "    \"\"\"Calculate match score using Gemini LLM and provide detailed analysis and improvement tips.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Given the following resume data in JSON format:\n",
    "    {resume_json}\n",
    "\n",
    "    And the following job description:\n",
    "    {job_description}\n",
    "\n",
    "    And the following job required skills:\n",
    "    {job_skills}\n",
    "\n",
    "    Analyze the resume data and determine the match score as a percentage.\n",
    "    List the skills that matched and the skills that did not match.\n",
    "    Provide a detailed explanation of why you gave the score, and provide advice to the candidate on how to improve the missing skills to match the job role.\n",
    "    Return the score, matched skills, unmatched skills, and explanation and improvement tips in a JSON format.\n",
    "    \"\"\"\n",
    "\n",
    "    response = model.generate_content(prompt)\n",
    "    try:\n",
    "        response_text = response.text\n",
    "        start_index = response_text.find('{')\n",
    "        end_index = response_text.rfind('}') + 1\n",
    "        json_output = json.loads(response_text[start_index:end_index])\n",
    "        return json_output\n",
    "    except (json.JSONDecodeError, ValueError):\n",
    "        return {\"score\": 0, \"matched_skills\": [], \"unmatched_skills\": [], \"explanation\": \"Failed to calculate match score.\", \"improvement_tips\": \"Failed to provide improvement tips.\"}\n",
    "\n",
    "def process_resume(file, job_role):\n",
    "    \"\"\"Process resume, extract data, and calculate match score using LLM.\"\"\"\n",
    "    resume_text = extract_text_from_pdf(file.name)\n",
    "    resume_json = extract_resume_data(resume_text)\n",
    "    job_description = JOB_ROLES[job_role][\"description\"]\n",
    "    job_skills = JOB_ROLES[job_role][\"skills\"]\n",
    "    match_result = calculate_match_score_with_llm(resume_json, job_description, job_skills)\n",
    "    matched_skills = match_result.get('matched_skills', [])\n",
    "    unmatched_skills = match_result.get('unmatched_skills', [])\n",
    "    job_skills_set = JOB_ROLES[job_role]['skills']\n",
    "    calculated_score = 0\n",
    "    if len(job_skills_set) > 0:\n",
    "        calculated_score = len(matched_skills) / len(job_skills_set) * 100\n",
    "    return {\n",
    "        \"match_score\": calculated_score,\n",
    "        \"matched_skills\": matched_skills,\n",
    "        \"unmatched_skills\": unmatched_skills,\n",
    "        \"job_description\": job_description,\n",
    "        \"resume_data\": resume_json\n",
    "    }\n",
    "\n",
    "# Create the Gradio interface for file upload and job role selection\n",
    "def gradio_interface():\n",
    "    job_roles = list(JOB_ROLES.keys())\n",
    "\n",
    "    def gradio_function(resume_file, job_role):\n",
    "        return process_resume(resume_file, job_role)\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=gradio_function,\n",
    "        inputs=[gr.File(label=\"Upload Resume\"), gr.Dropdown(choices=job_roles, label=\"Job Role\", value=job_roles[0])],\n",
    "        outputs=\"json\"\n",
    "    )\n",
    "\n",
    "    iface.launch()\n",
    "\n",
    "# Start Gradio interface\n",
    "gradio_interface()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd9627e-e19e-47b0-882c-dda17fec056b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf224e-958f-47d8-994f-3a896fb8c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70039a47-9796-49c8-a12b-6d29620eec9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f5f34-504a-4755-bb6d-bd41bc8acafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a505c3e-4d44-49df-b8fa-79854c7c09c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
