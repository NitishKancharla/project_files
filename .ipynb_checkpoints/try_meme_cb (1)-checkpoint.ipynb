{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f1795da-13a8-49c5-95a9-b84e31f0b281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (5.10.0)\n",
      "Requirement already satisfied: openai in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (1.59.3)\n",
      "Requirement already satisfied: requests in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (4.8.0)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.5.0)\n",
      "Requirement already satisfied: gradio-client==1.5.3 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (1.5.3)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.27.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.26.5)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (3.1.5)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (3.10.13)\n",
      "Requirement already satisfied: packaging in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (11.1.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (2.10.4)\n",
      "Requirement already satisfied: pydub in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.0.20)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.8.6)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio) (0.34.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio-client==1.5.3->gradio) (2024.9.0)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from gradio-client==1.5.3->gradio) (14.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pydantic>=2.0->gradio) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio openai requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0cd7612-aa7e-483c-b9a1-e7f3c2f34b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â � \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â � \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ´ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ¦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â § \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â ‡ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest â � \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest â ‹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest â ™ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest â ¹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1G\u001b[A\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling dde5aa3fc5ff... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 2.0 GB                         \n",
      "pulling 966de95ca8a6... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 1.4 KB                         \n",
      "pulling fcc5a6bec9da... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 7.7 KB                         \n",
      "pulling a70ff7e570d9... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–� 6.0 KB                         \n",
      "pulling 56bb8bd477a5... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�   96 B                         \n",
      "pulling 34bb5ab01051... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–�  561 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "# Ensure the Ollama server is running and the model is pulled\n",
    "!ollama pull llama3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211cac7f-e8c5-4359-9a97-ac31cc09935e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74074276-e99e-4b44-99eb-a1de0c226db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GAD\\anaconda3\\envs\\llms\\Lib\\site-packages\\gradio\\interface.py:403: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import gradio as gr\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Initialize the OpenAI client for Ollama integration\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "# Define the System message\n",
    "system_message = \"You are a highly knowledgeable technical expert who can generate funny meme dialogues based on user emotions. Use humor and creativity to respond.\"\n",
    "\n",
    "# This function will handle the user's query based on emotion and generate meme dialogues\n",
    "def generate_meme_dialogue(emotion, message, history):\n",
    "    \"\"\"\n",
    "    Takes an emotion, a message, and returns a meme-style dialogue.\n",
    "    \n",
    "    Args:\n",
    "        emotion (str): The emotional context (e.g., 'happy', 'sad', 'angry').\n",
    "        message (str): The user's message.\n",
    "        history (list): Conversation history\n",
    "        \n",
    "    Returns:\n",
    "        str: The meme-style response.\n",
    "        list: Updated conversation history.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make sure history is always a list (if None, initialize as an empty list)\n",
    "        history = history or []\n",
    "        \n",
    "        # Create a prompt that includes the user's emotion and message\n",
    "        prompt = (\n",
    "            f\"Generate a funny meme dialogue based on the emotion '{emotion}' and the following message:\\n\\n\"\n",
    "            f\"Message: {message}\\n\\n\"\n",
    "            \"Response (meme dialogue):\"\n",
    "        )\n",
    "        \n",
    "        # Make a request to the model\n",
    "        response = ollama_via_openai.completions.create(\n",
    "            model=MODEL,  # Llama model\n",
    "            prompt=prompt,\n",
    "            max_tokens=100,  # Short meme dialogues\n",
    "            temperature=0.9,  # Allow creativity in the responses\n",
    "        )\n",
    "        \n",
    "        # Extract the meme dialogue from the response\n",
    "        meme_dialogue = response.choices[0].text.strip()\n",
    "        \n",
    "        # Append the response to history\n",
    "        history.append({\"role\": \"assistant\", \"content\": meme_dialogue})\n",
    "        \n",
    "        return meme_dialogue, history\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\", history\n",
    "\n",
    "\n",
    "# Define the Gradio UI and chat function\n",
    "def chat_with_meme_emotion(message, emotion, history):\n",
    "    \"\"\"\n",
    "    Handles the user's message and generates meme dialogue based on the emotion.\n",
    "    \n",
    "    Args:\n",
    "        message (str): The user's message.\n",
    "        emotion (str): The user's emotion.\n",
    "        history (list): Conversation history.\n",
    "        \n",
    "    Returns:\n",
    "        str: The meme-style assistant's response.\n",
    "        list: Updated history.\n",
    "    \"\"\"\n",
    "    # Ensure history is a list (if None, initialize as an empty list)\n",
    "    history = history or []\n",
    "    \n",
    "    # Call the function to generate meme dialogue\n",
    "    response, history = generate_meme_dialogue(emotion, message, history)\n",
    "    \n",
    "    return response, history\n",
    "\n",
    "\n",
    "# Initialize the Gradio interface for chatbot-style interaction\n",
    "gr.Interface(\n",
    "    fn=chat_with_meme_emotion,\n",
    "    inputs=[gr.Textbox(label=\"Enter Your Message\", placeholder=\"Type your message here...\", lines=2),\n",
    "            gr.Dropdown(choices=[\"happy\", \"sad\", \"angry\", \"surprised\", \"confused\"], label=\"Select Emotion\"),\n",
    "            gr.State()],\n",
    "    outputs=[gr.Textbox(label=\"Generated Meme Dialogue\", interactive=False), gr.State()],\n",
    "    live=False,  # Disable real-time submission\n",
    "    title=\"Meme Dialogue Generator\",\n",
    "    description=\"Enter a message and select an emotion to generate a meme-style dialogue.\",\n",
    "    allow_flagging=\"never\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee545e0f-af8b-45ec-b2b1-9821b462337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: torch in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (0.26.5)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (0.5.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from datasets) (3.11.11)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from requests->transformers) (2024.12.14)\n",
      "Requirement already satisfied: colorama in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\gad\\anaconda3\\envs\\llms\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers datasets torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1d838df-fd6b-48d7-bfe9-bc31638f2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['meme_id', 'text', 'emotion_label'],\n",
      "        num_rows: 5100\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset from the correct file path\n",
    "dataset = load_dataset('csv', data_files={'train': 'data.csv'})\n",
    "\n",
    "# Check the structure of the dataset\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7dea700-2541-4e7f-bc54-b045485c5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Enter your Hugging Face token here\n",
    "login(token='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')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4763af62-5d08-42b7-b652-944af68b1008",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"  # Model running locally via Ollama\n",
    "\n",
    "# Load the dataset\n",
    "data_path = \"data.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Tokenize the dataset (you may adjust based on your dataset's structure)\n",
    "def tokenize_function(row):\n",
    "    input_text = f\"Emotion: {row['emotion_label']}, Message: {row['text']}\"\n",
    "    return input_text\n",
    "\n",
    "# Apply tokenization\n",
    "df['input_text'] = df.apply(tokenize_function, axis=1)\n",
    "\n",
    "# Function to send requests to Ollama for fine-tuning\n",
    "def fine_tune_llama(dataset):\n",
    "    for index, row in dataset.iterrows():\n",
    "        payload = {\n",
    "            \"model\": MODEL,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"user\", \"content\": row['input_text']},\n",
    "                {\"role\": \"assistant\", \"content\": row['emotion_label']}  # Using the emotion as a response for fine-tuning\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        response = requests.post(OLLAMA_API, headers=HEADERS, data=json.dumps(payload))\n",
    "\n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fine-tuning row {index}: {response.text}\")\n",
    "\n",
    "# Fine-tune with tokenized dataset\n",
    "fine_tune_llama(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a939654a-99ee-4656-9104-b1536c283ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
