{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5eca33c-575f-4f8d-9062-bebc846d266e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7900/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7900/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7900\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pdfplumber\n",
    "import docx\n",
    "import gradio as gr\n",
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants for Llama API\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"  # Llama API endpoint\n",
    "MODEL = \"llama3.2\"  # Llama model version\n",
    "\n",
    "# Extract structured information from resume using Llama\n",
    "EXTRACT_FEATURES_FROM_RESUME = \"\"\"\n",
    "Extract the following structured information from the resume:\n",
    "{\n",
    "    \"personal\": {\n",
    "        \"name\": \"\",\n",
    "        \"email\": \"\",\n",
    "        \"phone\": \"\",\n",
    "        \"linkedin\": \"\",\n",
    "        \"github\": \"\",\n",
    "        \"research_publications\": []\n",
    "    },\n",
    "    \"skills\": [\n",
    "        {\n",
    "            \"name\": \"\",\n",
    "            \"type\": \"technical\" or \"soft\",\n",
    "            \"proficiency\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"education\": [\n",
    "        {\n",
    "            \"degree\": \"\",\n",
    "            \"institution\": \"\",\n",
    "            \"year\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"work_experience\": [\n",
    "        {\n",
    "            \"company\": \"\",\n",
    "            \"role\": \"\",\n",
    "            \"duration\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"overall_experience\": 0\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Function to extract text from the resume (PDF or DOCX)\n",
    "def extract_text_from_resume(file_path):\n",
    "    text = \"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            text = \"\\n\".join([page.extract_text() for page in pdf.pages if page.extract_text()])\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text.strip()\n",
    "\n",
    "# Function to send the extracted text to Llama for information extraction\n",
    "def extract_data_from_llama(text):\n",
    "    prompt = EXTRACT_FEATURES_FROM_RESUME  # Prompt for Llama API\n",
    "    payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"input\": text,\n",
    "        \"prompt\": prompt\n",
    "    }\n",
    "\n",
    "    # Sending the request to Llama API\n",
    "    response = requests.post(OLLAMA_API, json=payload)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Return structured information from Llama\n",
    "    else:\n",
    "        return {\"error\": \"Failed to extract data from resume. Check the API.\"}\n",
    "\n",
    "# Function to calculate match score between resume and job role\n",
    "def calculate_match(extracted_data, job_role):\n",
    "    job_requirements = {\n",
    "        \"Software Engineer\": {\n",
    "            \"technical_skills\": [\"Python\", \"Java\", \"Cloud Computing\", \"Docker\", \"Kubernetes\", \"CI/CD\", \"Git\", \"SQL\", \"REST APIs\"],\n",
    "            \"soft_skills\": [\"Problem Solving\", \"Teamwork\", \"Communication\", \"Agile Methodology\", \"Critical Thinking\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"linkedin\"],\n",
    "            \"min_experience\": 2\n",
    "        },\n",
    "        \"Data Scientist\": {\n",
    "            \"technical_skills\": [\"Machine Learning\", \"Deep Learning\", \"Data Visualization\", \"Python\", \"R\", \"SQL\", \"Pandas\", \"NumPy\", \"Scikit-learn\", \"TensorFlow\", \"Keras\"],\n",
    "            \"soft_skills\": [\"Analytical Thinking\", \"Communication\", \"Storytelling\", \"Problem Solving\", \"Research Skills\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"github\"],\n",
    "            \"min_experience\": 1.5\n",
    "        },\n",
    "        \"AI Engineer\": {\n",
    "            \"technical_skills\": [\"Neural Networks\", \"NLP\", \"Computer Vision\", \"TensorFlow\", \"PyTorch\", \"Deep Learning\", \"Python\", \"Machine Learning\", \"Keras\"],\n",
    "            \"soft_skills\": [\"Research Skills\", \"Innovation\", \"Problem Solving\", \"Analytical Thinking\", \"Creativity\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"research_publications\"],\n",
    "            \"min_experience\": 2\n",
    "        },\n",
    "        \"Cybersecurity Analyst\": {\n",
    "            \"technical_skills\": [\"Ethical Hacking\", \"Threat Detection\", \"Network Security\", \"Penetration Testing\", \"SIEM\", \"Firewall Configuration\", \"Vulnerability Assessment\", \"Security Protocols\"],\n",
    "            \"soft_skills\": [\"Attention to Detail\", \"Analytical Thinking\", \"Risk Assessment\", \"Problem Solving\", \"Communication\"],\n",
    "            \"required_info\": [\"email\", \"phone\"],\n",
    "            \"min_experience\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Get job role requirements\n",
    "    requirements = job_requirements.get(job_role, {})\n",
    "\n",
    "    # Extract candidate skills\n",
    "    candidate_skills = {\n",
    "        \"technical_skills\": [skill[\"name\"] for skill in extracted_data.get(\"skills\", []) if skill.get(\"type\") == \"technical\"],\n",
    "        \"soft_skills\": [skill[\"name\"] for skill in extracted_data.get(\"skills\", []) if skill.get(\"type\") == \"soft\"]\n",
    "    }\n",
    "\n",
    "    # Match skills\n",
    "    matched_technical = [skill for skill in requirements.get(\"technical_skills\", []) if skill in candidate_skills[\"technical_skills\"]]\n",
    "    missing_technical = [skill for skill in requirements.get(\"technical_skills\", []) if skill not in candidate_skills[\"technical_skills\"]]\n",
    "    matched_soft = [skill for skill in requirements.get(\"soft_skills\", []) if skill in candidate_skills[\"soft_skills\"]]\n",
    "    missing_soft = [skill for skill in requirements.get(\"soft_skills\", []) if skill not in candidate_skills[\"soft_skills\"]]\n",
    "\n",
    "    # Missing personal info\n",
    "    missing_info = [info for info in requirements.get(\"required_info\", []) if not extracted_data.get(\"personal\", {}).get(info)]\n",
    "\n",
    "    # Experience check\n",
    "    experience = extracted_data.get(\"overall_experience\", 0)\n",
    "    meets_experience = experience >= requirements.get(\"min_experience\", 0)\n",
    "\n",
    "    # Match Score Calculation\n",
    "    technical_weight = 0.4\n",
    "    soft_skills_weight = 0.2\n",
    "    experience_weight = 0.2\n",
    "    info_weight = 0.2\n",
    "\n",
    "    technical_score = (len(matched_technical) / max(len(requirements.get(\"technical_skills\", [])), 1)) * 100 * technical_weight\n",
    "    soft_skills_score = (len(matched_soft) / max(len(requirements.get(\"soft_skills\", [])), 1)) * 100 * soft_skills_weight\n",
    "    experience_score = (experience / max(requirements.get(\"min_experience\", 1), 1)) * 100 * experience_weight\n",
    "    info_score = ((len(requirements.get(\"required_info\", [])) - len(missing_info)) / max(len(requirements.get(\"required_info\", [])), 1)) * 100 * info_weight\n",
    "\n",
    "    overall_score = round(technical_score + soft_skills_score + experience_score + info_score, 2)\n",
    "\n",
    "    # Return the detailed result\n",
    "    return {\n",
    "        \"Job Role\": job_role,\n",
    "        \"Overall Match Score\": f\"{overall_score}%\",\n",
    "        \"Matched Technical Skills\": matched_technical,\n",
    "        \"Missing Technical Skills\": missing_technical,\n",
    "        \"Matched Soft Skills\": matched_soft,\n",
    "        \"Missing Soft Skills\": missing_soft,\n",
    "        \"Experience\": f\"{experience} years (Required: {requirements.get('min_experience', 0)} years)\",\n",
    "        \"Missing Personal Info\": missing_info\n",
    "    }\n",
    "\n",
    "# Function to process the resume and compute match\n",
    "def process_resume(file, job_role):\n",
    "    if not file:\n",
    "        return \"Please upload a resume.\"\n",
    "\n",
    "    file_path = file.name\n",
    "    text = extract_text_from_resume(file_path)\n",
    "\n",
    "    if not text:\n",
    "        return \"Could not extract text from the resume.\"\n",
    "\n",
    "    # Extract data from the resume using Llama\n",
    "    extracted_data = extract_data_from_llama(text)\n",
    "    \n",
    "    if \"error\" in extracted_data:\n",
    "        return extracted_data[\"error\"]\n",
    "\n",
    "    # Calculate match score for the job role\n",
    "    return calculate_match(extracted_data, job_role)\n",
    "\n",
    "# Gradio Interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Resume Matching System\")\n",
    "    file_input = gr.File(label=\"Upload Resume (PDF/DOCX)\")\n",
    "    job_role_input = gr.Dropdown(choices=[\"Software Engineer\", \"Data Scientist\", \"AI Engineer\", \"Cybersecurity Analyst\"], label=\"Select Job Role\")\n",
    "    submit_button = gr.Button(\"Analyze Resume\")\n",
    "    output = gr.JSON(label=\"Match Results\")\n",
    "\n",
    "    submit_button.click(process_resume, inputs=[file_input, job_role_input], outputs=output)\n",
    "\n",
    "# Launch the Gradio app\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21bac9ed-21e0-4f10-9f29-692c54dd5aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw API Response: {\n",
      "    \"personal\": {\n",
      "        \"name\": \"\",\n",
      "        \"email\": \"suryavishal2002@gmail.com\",\n",
      "        \"phone\": \"+91 8500031155\",\n",
      "        \"linkedin\": \"https://www.linkedin.com/in/surya-vishal-ganti/\",\n",
      "        \"github\": \"\",\n",
      "        \"research_publications\": []\n",
      "    },\n",
      "    \"skills\": [\n",
      "        {\n",
      "            \"name\": \"Python, SQL, Pandas, NumPy, Scikit-Learn, Matplotlib, OpenCV, TensorFlow, Machine Learning, Deep Learning\",\n",
      "            \"type\": \"technical\"\n",
      "        },\n",
      "        {\n",
      "            \"name\": \"Communication, Presentation, Teamwork, Problem-Solving, Time Management\",\n",
      "            \"type\": \"soft\"\n",
      "        }\n",
      "    ],\n",
      "    \"education\": [\n",
      "        {\n",
      "            \"degree\": \"B. Tech\",\n",
      "            \"institution\": \"Anil Neerukonda Institute of Technology and Sciences(ANITS) Tagarapuvalasa, Vizag\",\n",
      "            \"year\": \"November 2021 - April 2024\"\n",
      "        },\n",
      "        {\n",
      "            \"degree\": \"Diploma in Electrical and Electronics Engineering\",\n",
      "            \"institution\": \"Government Polytechnic Srikakulam, Srikakulam\",\n",
      "            \"year\": \"July 2018 - October 2021\"\n",
      "        }\n",
      "    ],\n",
      "    \"work_experience\": [\n",
      "        {\n",
      "            \"company\": \"Tekworks Enterprises\",\n",
      "            \"role\": \"Graduate Apprentice Developer (GAD)\",\n",
      "            \"duration\": \"November 2024 - Present\"\n",
      "        },\n",
      "        {\n",
      "            \"company\": \"\",\n",
      "            \"role\": \"\",\n",
      "            \"duration\": \"\"\n",
      "        }\n",
      "    ],\n",
      "    \"overall_experience\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import pdfplumber\n",
    "import docx\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Prompt for feature extraction\n",
    "EXTRACT_FEATURES_FROM_RESUME = \"\"\"\n",
    "Extract the following structured information from the resume:\n",
    "{\n",
    "    \"personal\": {\n",
    "        \"name\": \"\",\n",
    "        \"email\": \"\",\n",
    "        \"phone\": \"\",\n",
    "        \"linkedin\": \"\",\n",
    "        \"github\": \"\",\n",
    "        \"research_publications\": []\n",
    "    },\n",
    "    \"skills\": [\n",
    "        {\n",
    "            \"name\": \"\",\n",
    "            \"type\": \"technical\" or \"soft\",\n",
    "            \"proficiency\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"education\": [\n",
    "        {\n",
    "            \"degree\": \"\",\n",
    "            \"institution\": \"\",\n",
    "            \"year\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"work_experience\": [\n",
    "        {\n",
    "            \"company\": \"\",\n",
    "            \"role\": \"\",\n",
    "            \"duration\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"overall_experience\": 0  # Total years of experience\n",
    "}\n",
    "\n",
    "Rules:\n",
    "1. Ensure all keys are present, use empty strings/lists if not found\n",
    "2. Categorize skills as 'technical' or 'soft'\n",
    "3. Calculate overall experience from work experience entries\n",
    "4. Extract all relevant details from the resume\n",
    "5. Provide response in strict JSON format\n",
    "\"\"\"\n",
    "\n",
    "# Initialize OpenAI client for Ollama\n",
    "ollama_via_openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "# Function to extract text from PDF or DOCX\n",
    "def extract_text_from_resume(file_path):\n",
    "    text = \"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
    "    return text.strip()\n",
    "\n",
    "# Function to calculate years of experience from a work duration string\n",
    "def calculate_experience_years(duration):\n",
    "    try:\n",
    "        months_in_year = 12\n",
    "        # Split by space and look for year/month pattern\n",
    "        if \"year\" in duration.lower():\n",
    "            years = re.findall(r\"(\\d+)\\s*year\", duration.lower())\n",
    "            if years:\n",
    "                return float(years[0])\n",
    "        if \"month\" in duration.lower():\n",
    "            months = re.findall(r\"(\\d+)\\s*month\", duration.lower())\n",
    "            if months:\n",
    "                return float(months[0]) / months_in_year\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating experience: {e}\")\n",
    "    return 0\n",
    "\n",
    "# Enhanced Function to calculate match score & provide detailed insights\n",
    "def calculate_match(extracted_data, job_description):\n",
    "    # Comprehensive skill requirements for different job roles\n",
    "    required_skills = {\n",
    "        \"Software Engineer\": {\n",
    "            \"technical\": [\"Python\", \"Java\", \"Cloud Computing\", \"Docker\", \"Kubernetes\", \"CI/CD\", \"Git\"],\n",
    "            \"soft_skills\": [\"Problem Solving\", \"Teamwork\", \"Communication\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"linkedin\"]\n",
    "        },\n",
    "        \"Data Scientist\": {\n",
    "            \"technical\": [\"Machine Learning\", \"Deep Learning\", \"Data Visualization\", \"Python\", \"R\", \"SQL\", \"Pandas\", \"NumPy\", \"Scikit-learn\"],\n",
    "            \"soft_skills\": [\"Analytical Thinking\", \"Communication\", \"Storytelling\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"github\"]\n",
    "        },\n",
    "        \"AI Engineer\": {\n",
    "            \"technical\": [\"Neural Networks\", \"NLP\", \"Computer Vision\", \"TensorFlow\", \"PyTorch\", \"Deep Learning\", \"Python\"],\n",
    "            \"soft_skills\": [\"Research Skills\", \"Innovation\", \"Problem Solving\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"research_publications\"]\n",
    "        },\n",
    "        \"Cybersecurity Analyst\": {\n",
    "            \"technical\": [\"Ethical Hacking\", \"Threat Detection\", \"Network Security\", \"Penetration Testing\", \"SIEM\", \"Firewall Configuration\"],\n",
    "            \"soft_skills\": [\"Attention to Detail\", \"Analytical Thinking\", \"Risk Assessment\"],\n",
    "            \"required_info\": [\"email\", \"phone\", \"security_certifications\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Get job role from job description\n",
    "    job_role = job_description.split(\"with \")[-1].split(\" experience\")[0]\n",
    "    job_skills = required_skills.get(job_role, {})\n",
    "    \n",
    "    # Extract skills from resume\n",
    "    extracted_skills = {\n",
    "        \"technical_skills\": [skill[\"name\"] for skill in extracted_data.get(\"skills\", []) if skill.get(\"type\") == \"technical\"],\n",
    "        \"soft_skills\": [skill[\"name\"] for skill in extracted_data.get(\"skills\", []) if skill.get(\"type\") == \"soft\"]\n",
    "    }\n",
    "    \n",
    "    # Skill Matching\n",
    "    matched_technical_skills = [skill for skill in job_skills.get(\"technical\", []) if skill in extracted_skills[\"technical_skills\"]]\n",
    "    missing_technical_skills = [skill for skill in job_skills.get(\"technical\", []) if skill not in extracted_skills[\"technical_skills\"]]\n",
    "    \n",
    "    matched_soft_skills = [skill for skill in job_skills.get(\"soft_skills\", []) if skill in extracted_skills[\"soft_skills\"]]\n",
    "    missing_soft_skills = [skill for skill in job_skills.get(\"soft_skills\", []) if skill not in extracted_skills[\"soft_skills\"]]\n",
    "    \n",
    "    # Missing Personal Information\n",
    "    missing_personal_info = [info for info in job_skills.get(\"required_info\", []) \n",
    "                              if not extracted_data.get(\"personal\", {}).get(info)]\n",
    "    \n",
    "    # Match Score Calculation\n",
    "    technical_skill_weight = 0.4  # 40% importance for technical skills\n",
    "    soft_skill_weight = 0.2       # 20% importance for soft skills\n",
    "    experience_weight = 0.2       # 20% importance for experience\n",
    "    info_completeness_weight = 0.2  # 20% importance for personal info completeness\n",
    "    \n",
    "    # Technical Skills Score\n",
    "    technical_skill_score = min(1.0, len(matched_technical_skills) / len(job_skills.get(\"technical\", [1]))) * technical_skill_weight * 100\n",
    "    \n",
    "    # Soft Skills Score\n",
    "    soft_skill_score = min(1.0, len(matched_soft_skills) / len(job_skills.get(\"soft_skills\", [1]))) * soft_skill_weight * 100\n",
    "    \n",
    "    # Experience Score\n",
    "    experience_score = min(50, extracted_data.get(\"overall_experience\", 0) * 10) * experience_weight\n",
    "    \n",
    "    # Information Completeness Score\n",
    "    info_completeness_score = (1 - (len(missing_personal_info) / len(job_skills.get(\"required_info\", [1])))) * info_completeness_weight * 100\n",
    "    \n",
    "    # Total Match Score\n",
    "    match_score = round(technical_skill_score + soft_skill_score + experience_score + info_completeness_score, 2)\n",
    "    \n",
    "    # Detailed Match Analysis\n",
    "    match_breakdown = {\n",
    "        \"technical_skill_score\": round(technical_skill_score, 2),\n",
    "        \"soft_skill_score\": round(soft_skill_score, 2),\n",
    "        \"experience_score\": round(experience_score, 2),\n",
    "        \"info_completeness_score\": round(info_completeness_score, 2)\n",
    "    }\n",
    "    \n",
    "    # Update extracted data with match details\n",
    "    extracted_data.update({\n",
    "        \"match_score\": match_score,\n",
    "        \"match_breakdown\": match_breakdown,\n",
    "        \"skills_analysis\": {\n",
    "            \"matched_technical_skills\": matched_technical_skills,\n",
    "            \"missing_technical_skills\": missing_technical_skills,\n",
    "            \"matched_soft_skills\": matched_soft_skills,\n",
    "            \"missing_soft_skills\": missing_soft_skills\n",
    "        },\n",
    "        \"missing_personal_info\": missing_personal_info\n",
    "    })\n",
    "    \n",
    "    return extracted_data\n",
    "\n",
    "# Function to query Llama 3.2\n",
    "def query_llama_api(resume_text, job_description):\n",
    "    try:\n",
    "        prompt = f\"Resume Text: {resume_text}\\nJob Description: {job_description}\\n\\n{EXTRACT_FEATURES_FROM_RESUME}\\nEnsure the output is strictly in JSON format without any additional text.\"\n",
    "\n",
    "        response = ollama_via_openai.completions.create(\n",
    "            model=MODEL,\n",
    "            prompt=prompt,\n",
    "            max_tokens=1000,  # Increase to capture full JSON\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        raw_output = response.choices[0].text.strip()\n",
    "        print(\"Raw API Response:\", raw_output)  # Debugging step\n",
    "\n",
    "        match = re.search(r\"\\{.*\\}\", raw_output, re.DOTALL)\n",
    "        if match:\n",
    "            parsed_data = json.loads(match.group(0))\n",
    "            \n",
    "            # Calculate overall experience\n",
    "            if parsed_data.get(\"work_experience\"):\n",
    "                experience_years = sum(\n",
    "                    calculate_experience_years(exp.get(\"duration\", \"0\"))\n",
    "                    for exp in parsed_data[\"work_experience\"] \n",
    "                    if exp.get(\"duration\")\n",
    "                )\n",
    "                parsed_data[\"overall_experience\"] = experience_years\n",
    "            else:\n",
    "                parsed_data[\"overall_experience\"] = 0\n",
    "            \n",
    "            return parsed_data\n",
    "        else:\n",
    "            return {\"error\": \"Invalid JSON extracted from response\"}\n",
    "\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON from API response\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"API request failed: {str(e)}\"}\n",
    "\n",
    "# Function to process the resume\n",
    "def process_resume(file, job_role):\n",
    "    try:\n",
    "        file_path = file.name\n",
    "        resume_text = extract_text_from_resume(file_path)\n",
    "\n",
    "        job_descriptions = {\n",
    "            \"Software Engineer\": \"Looking for a software engineer with Python, Java, and cloud experience.\",\n",
    "            \"Data Scientist\": \"Seeking a data scientist proficient in machine learning, deep learning, and data visualization.\",\n",
    "            \"AI Engineer\": \"Hiring an AI Engineer with expertise in neural networks, NLP, and computer vision.\",\n",
    "            \"Cybersecurity Analyst\": \"Looking for a cybersecurity analyst skilled in ethical hacking and threat detection.\"\n",
    "        }\n",
    "\n",
    "        job_description = job_descriptions.get(job_role, \"No JD available.\")\n",
    "        extracted_data = query_llama_api(resume_text, job_description)\n",
    "        \n",
    "        # Only calculate match if extraction was successful\n",
    "        if not extracted_data.get(\"error\"):\n",
    "            matched_data = calculate_match(extracted_data, job_description)\n",
    "            return json.dumps(matched_data, indent=4)\n",
    "        else:\n",
    "            return json.dumps(extracted_data, indent=4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_resume,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload Resume (PDF/DOCX)\"),\n",
    "        gr.Dropdown(\n",
    "            choices=[\"Software Engineer\", \"Data Scientist\", \"AI Engineer\", \"Cybersecurity Analyst\"],\n",
    "            label=\"Select Job Role\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=gr.JSON(label=\"Extracted Resume Data & Match Analysis\"),\n",
    "    title=\"Resume Analyzer & JD Matcher\",\n",
    "    description=\"Upload a resume and select a job role to extract structured information, match percentage, and missing information.\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "588ef3d7-8e12-4a7c-8a6b-4e14d48ad410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 2113, in process_api\n",
      "    data = await self.postprocess_data(block_fn, result[\"prediction\"], state)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/blocks.py\", line 1919, in postprocess_data\n",
      "    prediction_value = block.postprocess(prediction_value)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/nitish/opt/anaconda3/envs/llms/lib/python3.11/site-packages/gradio/components/json_component.py\", line 115, in postprocess\n",
      "    return JsonData(orjson.loads(value))\n",
      "                    ^^^^^^^^^^^^^^^^^^^\n",
      "orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import orjson\n",
    "import pdfplumber\n",
    "import docx\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# Constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "# Prompt for feature extraction\n",
    "EXTRACT_FEATURES_FROM_RESUME = \"\"\"\n",
    "Extract the following structured information from the resume:\n",
    "{\n",
    "    \"personal\": {\n",
    "        \"name\": \"\",\n",
    "        \"email\": \"\",\n",
    "        \"phone\": \"\",\n",
    "        \"linkedin\": \"\",\n",
    "        \"github\": \"\",\n",
    "        \"research_publications\": []\n",
    "    },\n",
    "    \"skills\": [\n",
    "        {\n",
    "            \"name\": \"\",\n",
    "            \"type\": \"technical\" or \"soft\",\n",
    "            \"proficiency\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"education\": [\n",
    "        {\n",
    "            \"degree\": \"\",\n",
    "            \"institution\": \"\",\n",
    "            \"year\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"work_experience\": [\n",
    "        {\n",
    "            \"company\": \"\",\n",
    "            \"role\": \"\",\n",
    "            \"duration\": \"\"\n",
    "        }\n",
    "    ],\n",
    "    \"overall_experience\": 0  # Total years of experience\n",
    "}\n",
    "\n",
    "Rules:\n",
    "1. Ensure all keys are present, use empty strings/lists if not found\n",
    "2. Categorize skills as 'technical' or 'soft'\n",
    "3. Calculate overall experience from work experience entries\n",
    "4. Extract all relevant details from the resume\n",
    "5. Provide response in strict JSON format\n",
    "\"\"\"\n",
    "\n",
    "# Initialize OpenAI client for Ollama\n",
    "ollama_via_openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "\n",
    "# Function to extract text from PDF or DOCX\n",
    "def extract_text_from_resume(file_path):\n",
    "    text = \"\"\n",
    "    if file_path.endswith(\".pdf\"):\n",
    "        with pdfplumber.open(file_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text += page.extract_text() + \"\\n\"\n",
    "    elif file_path.endswith(\".docx\"):\n",
    "        doc = docx.Document(file_path)\n",
    "        for para in doc.paragraphs:\n",
    "            text += para.text + \"\\n\"\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Use PDF or DOCX.\")\n",
    "    return text.strip()\n",
    "\n",
    "# Function to calculate years of experience from a work duration string\n",
    "def calculate_experience_years(duration):\n",
    "    try:\n",
    "        months_in_year = 12\n",
    "        if \"year\" in duration.lower():\n",
    "            years = re.findall(r\"(\\d+)\\s*year\", duration.lower())\n",
    "            if years:\n",
    "                return float(years[0])\n",
    "        if \"month\" in duration.lower():\n",
    "            months = re.findall(r\"(\\d+)\\s*month\", duration.lower())\n",
    "            if months:\n",
    "                return float(months[0]) / months_in_year\n",
    "    except Exception as e:\n",
    "        print(f\"Error in calculating experience: {e}\")\n",
    "    return 0\n",
    "\n",
    "# Function to query Llama for feature extraction\n",
    "def query_llama_api(resume_text, job_description):\n",
    "    try:\n",
    "        prompt = f\"Resume Text: {resume_text}\\nJob Description: {job_description}\\n\\n{EXTRACT_FEATURES_FROM_RESUME}\\nEnsure the output is strictly in JSON format without any additional text.\"\n",
    "\n",
    "        response = ollama_via_openai.completions.create(\n",
    "            model=MODEL,\n",
    "            prompt=prompt,\n",
    "            max_tokens=1000,  # Increase to capture full JSON\n",
    "            temperature=0.7,\n",
    "        )\n",
    "\n",
    "        raw_output = response.choices[0].text.strip()\n",
    "        print(\"Raw API Response:\", raw_output)  # Debugging step\n",
    "\n",
    "        # Check if the response contains valid JSON using a try-except block\n",
    "        try:\n",
    "            # Using orjson for more efficient JSON parsing\n",
    "            parsed_data = orjson.loads(raw_output)\n",
    "        except orjson.JSONDecodeError:\n",
    "            return {\"error\": \"Failed to parse JSON from API response\"}\n",
    "        \n",
    "        # Calculate overall experience\n",
    "        if parsed_data.get(\"work_experience\"):\n",
    "            experience_years = sum(\n",
    "                calculate_experience_years(exp.get(\"duration\", \"0\"))\n",
    "                for exp in parsed_data[\"work_experience\"] \n",
    "                if exp.get(\"duration\")\n",
    "            )\n",
    "            parsed_data[\"overall_experience\"] = experience_years\n",
    "        else:\n",
    "            parsed_data[\"overall_experience\"] = 0\n",
    "        \n",
    "        return parsed_data\n",
    "\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"API request failed: {str(e)}\"}\n",
    "\n",
    "# Function to match resume data with job description\n",
    "def match_resume_with_job_description(extracted_data, job_description):\n",
    "    job_skills = extract_job_skills(job_description)\n",
    "\n",
    "    matched_skills = match_skills(extracted_data, job_skills)\n",
    "\n",
    "    # Calculate the match score based on matched and missing skills\n",
    "    match_score = calculate_match_score(matched_skills, extracted_data, job_description)\n",
    "\n",
    "    return {\n",
    "        \"match_score\": match_score,\n",
    "        \"skills_analysis\": matched_skills,\n",
    "        \"personal_info\": check_missing_personal_info(extracted_data, job_description)\n",
    "    }\n",
    "\n",
    "# Extract relevant job skills from the job description using simple NLP\n",
    "def extract_job_skills(job_description):\n",
    "    technical_keywords = [\"Python\", \"Java\", \"Cloud Computing\", \"Docker\", \"Kubernetes\", \"CI/CD\", \"Git\", \"Machine Learning\", \"Deep Learning\", \"Data Visualization\", \"SQL\"]\n",
    "    soft_skills_keywords = [\"Problem Solving\", \"Teamwork\", \"Communication\", \"Analytical Thinking\", \"Innovation\"]\n",
    "\n",
    "    technical_skills = [skill for skill in technical_keywords if skill.lower() in job_description.lower()]\n",
    "    soft_skills = [skill for skill in soft_skills_keywords if skill.lower() in job_description.lower()]\n",
    "\n",
    "    return {\"technical\": technical_skills, \"soft_skills\": soft_skills}\n",
    "\n",
    "# Match extracted resume skills with job description skills\n",
    "def match_skills(extracted_data, job_skills):\n",
    "    matched_technical = [skill for skill in job_skills[\"technical\"] if any(resume_skill[\"name\"] == skill for resume_skill in extracted_data.get(\"skills\", []))]\n",
    "    matched_soft = [skill for skill in job_skills[\"soft_skills\"] if any(resume_skill[\"name\"] == skill for resume_skill in extracted_data.get(\"skills\", []))]\n",
    "\n",
    "    return {\n",
    "        \"matched_technical_skills\": matched_technical,\n",
    "        \"matched_soft_skills\": matched_soft,\n",
    "        \"missing_technical_skills\": [skill for skill in job_skills[\"technical\"] if skill not in matched_technical],\n",
    "        \"missing_soft_skills\": [skill for skill in job_skills[\"soft_skills\"] if skill not in matched_soft],\n",
    "    }\n",
    "\n",
    "# Calculate match score\n",
    "def calculate_match_score(matched_skills, extracted_data, job_description):\n",
    "    technical_score = len(matched_skills[\"matched_technical_skills\"]) / len(matched_skills[\"matched_technical_skills\"] + matched_skills[\"missing_technical_skills\"]) * 50\n",
    "    soft_score = len(matched_skills[\"matched_soft_skills\"]) / len(matched_skills[\"matched_soft_skills\"] + matched_skills[\"missing_soft_skills\"]) * 30\n",
    "    experience_score = min(50, extracted_data.get(\"overall_experience\", 0) * 10)\n",
    "    info_score = 20 if all(extracted_data.get(\"personal\", {}).get(field) for field in [\"email\", \"phone\", \"linkedin\"]) else 0\n",
    "\n",
    "    return round(technical_score + soft_score + experience_score + info_score, 2)\n",
    "\n",
    "# Check if required personal info is missing\n",
    "def check_missing_personal_info(extracted_data, job_description):\n",
    "    required_info = [\"email\", \"phone\", \"linkedin\", \"github\", \"research_publications\"]\n",
    "    missing_info = [field for field in required_info if not extracted_data.get(\"personal\", {}).get(field)]\n",
    "\n",
    "    return missing_info\n",
    "\n",
    "# Function to process the resume and job role\n",
    "def process_resume(file, job_role):\n",
    "    try:\n",
    "        file_path = file.name\n",
    "        resume_text = extract_text_from_resume(file_path)\n",
    "\n",
    "        extracted_data = query_llama_api(resume_text)\n",
    "        \n",
    "        if \"error\" in extracted_data:\n",
    "            return json.dumps(extracted_data, indent=4)\n",
    "\n",
    "        job_descriptions = {\n",
    "            \"Software Engineer\": \"Looking for a software engineer with Python, Java, and cloud experience.\",\n",
    "            \"Data Scientist\": \"Seeking a data scientist proficient in machine learning, deep learning, and data visualization.\",\n",
    "            \"AI Engineer\": \"Hiring an AI Engineer with expertise in neural networks, NLP, and computer vision.\",\n",
    "            \"Cybersecurity Analyst\": \"Looking for a cybersecurity analyst skilled in ethical hacking and threat detection.\"\n",
    "        }\n",
    "\n",
    "        job_description = job_descriptions.get(job_role, \"No JD available.\")\n",
    "        match_data = match_resume_with_job_description(extracted_data, job_description)\n",
    "        \n",
    "        return json.dumps(match_data, indent=4)\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Gradio Interface\n",
    "iface = gr.Interface(\n",
    "    fn=process_resume,\n",
    "    inputs=[\n",
    "        gr.File(label=\"Upload Resume (PDF/DOCX)\"),\n",
    "        gr.Dropdown(\n",
    "            choices=[\"Software Engineer\", \"Data Scientist\", \"AI Engineer\", \"Cybersecurity Analyst\"],\n",
    "            label=\"Select Job Role\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=gr.JSON(label=\"Extracted Resume Data & Match Analysis\"),\n",
    "    title=\"Resume Analyzer & JD Matcher\",\n",
    "    description=\"Upload a resume and select a job role to extract structured information, match percentage, and missing information.\",\n",
    ")\n",
    "\n",
    "# Launch the Gradio app\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeab963-edb6-4abd-a81b-5c85a239c0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
